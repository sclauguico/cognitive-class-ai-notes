{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Module 1: Basic Statistics and Data Types  \n",
    "\n",
    "## Local and Distributed Matrices\n",
    "\n",
    "## Lesson Objectives\n",
    "\n",
    "After completing this lesson, you should be able to:\n",
    "\n",
    "- Understand local and distributed matrices\n",
    "- Create dense and sparse matrices \n",
    "- Create different types of distributed matrices \n",
    "\n",
    "\n",
    "### Local Matrices \n",
    "- Natural extension of Vectors \n",
    "- Row and column indices are 0-based integers and values are doubles \n",
    "- Local matrices are stored on a single machine \n",
    "- MLlib's matrices can be either dense or sparse \n",
    "- Matrices are filled in column major order\n",
    "\n",
    "### Dense Matrices \n",
    "- A \"reshaped\" dense Vector \n",
    "- First two arguments specify dimensions of the matrix \n",
    "- Entries are stored in a single double array \n",
    "\n",
    "### A Dense Matrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://host.docker.internal:4041\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1669534057680)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/27 15:27:53 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.mllib.linalg.{Matrix, Matrices}\r\n",
       "res0: org.apache.spark.mllib.linalg.Matrix =\r\n",
       "1.0  2.0\r\n",
       "3.0  4.0\r\n",
       "5.0  6.0\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.linalg.{Matrix, Matrices}\n",
    "\n",
    "Matrices.dense(3, 2, Array(1, 3, 5, 2, 4, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrices in Spark: Compressed Sparse Column (CSC) format\n",
    "\n",
    "Rows: 5\n",
    "Columns: 4\n",
    "Column pointers: `(0, 0, 1, 2, 2)`\n",
    "Row Indices: `(1, 3)`\n",
    "Non-zero values: `(34.0, 55.0)`\n",
    "\n",
    "### Sparse Matrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m: org.apache.spark.mllib.linalg.Matrix =\r\n",
       "5 x 4 CSCMatrix\r\n",
       "(1,1) 34.0\r\n",
       "(3,2) 55.0\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val m = Matrices.sparse(5, 4, \n",
    "  Array(0, 0, 1, 2, 2), \n",
    "  Array(1, 3),\n",
    "  Array(34, 55)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Matrices \n",
    "\n",
    "Distributed Matrices are where Spark starts to deliver significant value. They are stored in one or more RDDs.\n",
    "\n",
    "Three types have been implemented: \n",
    "- `RowMatrix`\n",
    "- `IndexedMatrix`\n",
    "- `CoodinateMatrix`\n",
    "\n",
    "Conversions may require an expensive global shuffle.\n",
    "\n",
    "\n",
    "#### RowMatrix\n",
    "\n",
    "- The most basic type of distributed matrix \n",
    "- It has no meaningful row indices, being only a collection of feature vectors \n",
    "- Backed by an RDD of its rows, where each row is a local vector `RowMatrix` \n",
    "- Assumes the number of columns is small enough to be stored in a local vector\n",
    "- Can be easily created from an instance of `RDD[Vector]`\n",
    "\n",
    "\n",
    "### A Simple RowMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.rdd.RDD\r\n",
       "import org.apache.spark.mllib.linalg.distributed.RowMatrix\r\n",
       "import org.apache.spark.mllib.linalg.{Vector, Vectors}\r\n",
       "rows: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = ParallelCollectionRDD[0] at parallelize at <console>:29\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import  org.apache.spark.rdd.RDD\n",
    "import  org.apache.spark.mllib.linalg.distributed.RowMatrix\n",
    "import  org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
    "\n",
    "val rows: RDD[Vector] = sc.parallelize(Array(\n",
    "Vectors.dense(1.0, 2.0),\n",
    "Vectors.dense(4.0, 5.0), \n",
    "Vectors.dense(7.0, 8.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple RowMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mat: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@641976bb\r\n",
       "m: Long = 3\r\n",
       "n: Long = 2\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mat: RowMatrix = new RowMatrix(rows)\n",
    "\n",
    "val m= mat.numRows()\n",
    "val n= mat.numCols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndexedRowMatrix\n",
    "\n",
    "- Similar to a `RowMatrix`\n",
    "- But it has meaningful row indices, which can be used for identifying rows and executing joins\n",
    "- Backed by an RDD of indexed rows, where each row is a tuple containing an index (long-typed) and a local vector \n",
    "- Easily created from an instance of `RDD[IndexedRow]`\n",
    "- Can be converted to a `RowMatrix` by calling `toRowMatrix()`\n",
    "\n",
    "\n",
    "### A Simple IndexedRowMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix, RowMatrix}\r\n",
       "rows: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.IndexedRow] = ParallelCollectionRDD[1] at parallelize at <console>:31\r\n",
       "idxMat: org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix = org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix@2425a06b\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix, RowMatrix}\n",
    "\n",
    "val rows: RDD[IndexedRow] = sc.parallelize(Array(\n",
    "IndexedRow(0, Vectors.dense(1.0,2.0)),\n",
    "IndexedRow(1, Vectors.dense(4.0,5.0)),\n",
    "IndexedRow(2, Vectors.dense(7.0,8.0))))\n",
    "\n",
    "val idxMat: IndexedRowMatrix = new IndexedRowMatrix(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoordinateMatrix \n",
    "\n",
    "- Should be used only when both dimensions are huge and the matrix is very sparse\n",
    "- Backed up by an RDD of matrix entries, where each entry is a tuple `(i: Long, j: Long, value: Double)` where `i` is the row index `j` is the column index value is the entry value\n",
    "- Can be easily created from an instance of `RDD[MatrixEntry]`\n",
    "- Can be converted to an `IndexedRowMatrix` with sparse rows by calling `toIndexedRowMatrix()`\n",
    "\n",
    "\n",
    "### A Simple CoordinateMatrix Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.mllib.linalg.distributed.MatrixEntry\r\n",
       "import org.apache.spark.mllib.linalg.distributed.CoordinateMatrix\r\n",
       "entries: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = ParallelCollectionRDD[2] at parallelize at <console>:33\r\n",
       "coordMat: org.apache.spark.mllib.linalg.distributed.CoordinateMatrix = org.apache.spark.mllib.linalg.distributed.CoordinateMatrix@6f1e126\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.linalg.distributed.MatrixEntry\n",
    "import org.apache.spark.mllib.linalg.distributed.CoordinateMatrix\n",
    "\n",
    "val entries: RDD[MatrixEntry] = sc.parallelize(Array(\n",
    "MatrixEntry(0, 0, 9.0),\n",
    "MatrixEntry(1, 1, 8.0),\n",
    "MatrixEntry(2, 1, 6.0)))\n",
    "\n",
    "val coordMat: CoordinateMatrix = new CoordinateMatrix(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
