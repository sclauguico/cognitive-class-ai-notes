{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Module 5: Pipeline and Grid Search\n",
    "\n",
    "## Predicting Grant Applications: Building a Pipeline\n",
    "\n",
    "### Lesson Objectives\n",
    "\n",
    "* After completing this lesson, you should be able to extract useful information from the results of the grid search, including:\n",
    "  - the average area under the ROC curve for each combination of parameters\n",
    "  - the parameters of the best model\n",
    "  - the feature importances of the best model\n",
    "  \n",
    "### avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://host.docker.internal:4044\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1670056426962)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------------+---------+--------------+---------+--------------------+-------------+----------------+-------------+--------+----------+--------+-----------------------------------+--------------------------+----------------------------+----+----+----+----+------------+------------+--------------------+-------------------+\n",
      "|Grant_Application_ID| RFCD_Code|RFCD_Percentage| SEO_Code|SEO_Percentage|Person_ID|                Role|Year_of_Birth|Country_of_Birth|Home_Language| Dept_No|Faculty_No|With_PHD|No_of_Years_in_Uni_at_Time_of_Grant|Number_of_Successful_Grant|Number_of_Unsuccessful_Grant|  A2|   A|   B|   C|Grant_Status|Sponsor_Code| Contract_Value_Band|Grant_Category_Code|\n",
      "+--------------------+----------+---------------+---------+--------------+---------+--------------------+-------------+----------------+-------------+--------+----------+--------+-----------------------------------+--------------------------+----------------------------+----+----+----+----+------------+------------+--------------------+-------------------+\n",
      "|                   1|RFCD280199|          100.0|SEO700299|         100.0|    40572|  CHIEF_INVESTIGATOR|         1965|     AsiaPacific|    OtherLang|Dept3073| Faculty31|    null|                        DurationLT0|                         0|                           0|   4|   2|   0|   0|           1|  SponsorUnk|  ContractValueBandA|        GrantCatUnk|\n",
      "|                   2|RFCD280103|           30.0|SEO700103|          50.0|     9067|  CHIEF_INVESTIGATOR|         1960|       Australia|         null|Dept2538| Faculty25|     Yes|                       DurationGT15|                         0|                           0|   6|  12|   2|   2|           1|   Sponsor2B|  ContractValueBandB|        GrantCat10A|\n",
      "|                   3|RFCD321004|           60.0|SEO730105|          60.0|     5967|  CHIEF_INVESTIGATOR|         1955|       Australia|         null|Dept2923| Faculty25|     Yes|                      Duration5to10|                         0|                           0|   0|   3|   5|   2|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|RFCD321216|           40.0|SEO730207|          40.0|    27307|  CHIEF_INVESTIGATOR|         1950|       Australia|         null|Dept2923| Faculty25|    null|                        DurationLT0|                         0|                           0|   0|   0|   0|   0|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|      null|           null|     null|          null|    79652|  CHIEF_INVESTIGATOR|         1950|     AsiaPacific|         null|Dept2498| Faculty25|     Yes|                       DurationGT15|                         0|                           0|   1|   3|   3|   3|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   3|      null|           null|     null|          null|    11667|DELEGATED_RESEARCHER|         1950|       Australia|         null|Dept2548| Faculty25|    null|                       DurationGT15|                         0|                           0|   6|  14|  12|   2|           1|  Sponsor29A|  ContractValueBandA|        GrantCat10B|\n",
      "|                   4|RFCD270602|           50.0|SEO730106|          70.0|    78782|PRINCIPAL_SUPERVISOR|         1955|       Australia|         null|Dept2678| Faculty25|     Yes|                      Duration5to10|                         0|                           0|   0|   3|  13|   3|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   4|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   4|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   4|RFCD320602|           50.0|SEO730201|          30.0|    55337|  CHIEF_INVESTIGATOR|         1975|       Australia|         null|Dept2678| Faculty25|     Yes|                       Duration0to5|                         0|                           0|   0|   0|   0|   0|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   4|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   4|      null|           null|     null|          null|     null|STUD_CHIEF_INVEST...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           1|  Sponsor40D|  ContractValueBandC|        GrantCat10B|\n",
      "|                   5|RFCD260500|           34.0|SEO770199|         100.0|    13042|  CHIEF_INVESTIGATOR|         1965|   WesternEurope|         null|Dept2153| Faculty19|     Yes|                      Duration5to10|                         0|                           0|   3|   0|   1|   0|           0|  Sponsor59C|  ContractValueBandA|        GrantCat10A|\n",
      "|                   6|RFCD321204|          100.0|SEO730211|         100.0|   301472|  CHIEF_INVESTIGATOR|         1950|       Australia|         null|Dept2533| Faculty25|     Yes|                       Duration0to5|                         2|                           0|   7|  27|  27|   6|           1|   Sponsor4D|ContractValueBandUnk|        GrantCat10A|\n",
      "|                   7|RFCD270401|           20.0|     null|          null|    79742|  CHIEF_INVESTIGATOR|         1950|    GreatBritain|         null|Dept3028| Faculty31|    null|                        DurationLT0|                         0|                           0|   0|   7|  12|   4|           0|   Sponsor2B|ContractValueBandUnk|        GrantCat10A|\n",
      "|                   7|      null|           null|     null|          null|     null|EXT_CHIEF_INVESTI...|         null|            null|         null|    null|      null|    null|                        DurationUnk|                      null|                        null|null|null|null|null|           0|   Sponsor2B|ContractValueBandUnk|        GrantCat10A|\n",
      "|                   7|RFCD270203|           30.0|SEO770706|          40.0|    82602|  CHIEF_INVESTIGATOR|         1960|       Australia|         null|Dept3028| Faculty31|     Yes|                     Duration10to15|                         0|                           1|   0|   0|   0|   0|           0|   Sponsor2B|ContractValueBandUnk|        GrantCat10A|\n",
      "+--------------------+----------+---------------+---------+--------------+---------+--------------------+-------------+----------------+-------------+--------+----------+--------+-----------------------------------+--------------------------+----------------------------+----+----+----+----+------------+------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@72594949\r\n",
       "import spark.implicits._\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "data: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, RFCD_Code: string ... 22 more fields]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val data = spark.read.\n",
    "  format(\"com.databricks.spark.csv\").\n",
    "  option(\"delimiter\", \"\\t\").\n",
    "  option(\"header\", \"true\").\n",
    "  option(\"inferSchema\", \"true\").\n",
    "//   load(\"/resources/data/grantsPeople.csv\")\n",
    "  load(\"grantsPeople.csv\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+--------------------+----+----------+--------+---------+--------+\n",
      "|Grant_Application_ID|Grant_Status|Category_Code|          Value_Band|PHDs|paperscore|teamsize|successes|failures|\n",
      "+--------------------+------------+-------------+--------------------+----+----------+--------+---------+--------+\n",
      "|                   1|           1|  GrantCatUnk|  ContractValueBandA|null|        22|       1|        0|       0|\n",
      "|                   2|           1|  GrantCat10A|  ContractValueBandB|   1|        60|       1|        0|       0|\n",
      "|                   3|           1|  GrantCat10B|  ContractValueBandA|   2|        13|       7|        0|       0|\n",
      "|                   4|           1|  GrantCat10B|  ContractValueBandC|   2|         0|       6|        0|       0|\n",
      "|                   5|           0|  GrantCat10A|  ContractValueBandA|   1|        12|       1|        0|       0|\n",
      "|                   6|           1|  GrantCat10A|ContractValueBandUnk|   1|       109|       1|        2|       0|\n",
      "|                   7|           0|  GrantCat10A|ContractValueBandUnk|   2|        47|       4|        0|       1|\n",
      "|                   8|           0|  GrantCat30B|  ContractValueBandA|null|         0|       3|        0|       3|\n",
      "|                   9|           1|  GrantCat10A|  ContractValueBandH|   2|        35|       4|        2|       1|\n",
      "|                  10|           1|  GrantCat10A|ContractValueBandUnk|null|         4|       4|        0|       0|\n",
      "|                  11|           1|  GrantCat10A|  ContractValueBandG|   2|        20|       2|        1|       0|\n",
      "|                  12|           0|  GrantCat30B|ContractValueBandUnk|   1|        24|       2|        2|       7|\n",
      "|                  13|           1|  GrantCat10A|ContractValueBandUnk|null|        25|       1|        1|       1|\n",
      "|                  14|           0|  GrantCatUnk|ContractValueBandUnk|null|        24|       4|        0|       1|\n",
      "|                  15|           1|  GrantCat10A|ContractValueBandUnk|   3|        60|       5|        3|       5|\n",
      "|                  16|           0|  GrantCat10B|ContractValueBandUnk|   1|         0|       1|        0|       1|\n",
      "|                  17|           0|  GrantCat10A|ContractValueBandUnk|   1|        24|       1|        2|       7|\n",
      "|                  18|           1|  GrantCat50A|ContractValueBandUnk|   1|         6|       1|        1|       0|\n",
      "|                  19|           1|  GrantCat10A|  ContractValueBandF|   2|         0|       4|        2|       0|\n",
      "|                  20|           0|  GrantCat30B|  ContractValueBandA|null|         0|       1|        0|       1|\n",
      "+--------------------+------------+-------------+--------------------+----+----------+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "researchers: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, RFCD_Code: string ... 25 more fields]\r\n",
       "grants: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, Grant_Status: int ... 7 more fields]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val researchers = data.\n",
    "  withColumn (\"phd\", data(\"With_PHD\").equalTo(\"Yes\").cast(\"Int\")).\n",
    "  withColumn (\"CI\", data(\"Role\").equalTo(\"CHIEF_INVESTIGATOR\").cast(\"Int\")).\n",
    "  withColumn(\"paperscore\", data(\"A2\") * 4 + data(\"A\") * 3)\n",
    "\n",
    "val grants = researchers.groupBy(\"Grant_Application_ID\").agg(\n",
    "  max(\"Grant_Status\").as(\"Grant_Status\"),\n",
    "  max(\"Grant_Category_Code\").as(\"Category_Code\"),\n",
    "  max(\"Contract_Value_Band\").as(\"Value_Band\"),\n",
    "  sum(\"phd\").as(\"PHDs\"),\n",
    "  when(max(expr(\"paperscore * CI\")).isNull, 0).\n",
    "    otherwise(max(expr(\"paperscore * CI\"))).as(\"paperscore\"),\n",
    "  count(\"*\").as(\"teamsize\"),\n",
    "  when(sum(\"Number_of_Successful_Grant\").isNull, 0).\n",
    "    otherwise(sum(\"Number_of_Successful_Grant\")).as(\"successes\"),\n",
    "  when(sum(\"Number_of_Unsuccessful_Grant\").isNull, 0).\n",
    "    otherwise(sum(\"Number_of_Unsuccessful_Grant\")).as(\"failures\")\n",
    ")\n",
    "\n",
    "grants.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.StringIndexer\r\n",
       "value_band_indexer: org.apache.spark.ml.feature.StringIndexerModel = StringIndexerModel: uid=strIdx_2ac4c5292f7f, handleInvalid=error\r\n",
       "category_indexer: org.apache.spark.ml.feature.StringIndexerModel = StringIndexerModel: uid=strIdx_8ce2dc20f1b0, handleInvalid=error\r\n",
       "label_indexer: org.apache.spark.ml.feature.StringIndexerModel = StringIndexerModel: uid=strIdx_a826b719fc96, handleInvalid=error\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "val value_band_indexer = new StringIndexer().\n",
    "  setInputCol(\"Value_Band\").\n",
    "  setOutputCol(\"Value_index\").\n",
    "  fit(grants)\n",
    "  \n",
    "val category_indexer = new StringIndexer().\n",
    "  setInputCol(\"Category_Code\").\n",
    "  setOutputCol(\"Category_index\").\n",
    "  fit(grants)\n",
    "  \n",
    "val label_indexer = new StringIndexer().\n",
    "  setInputCol(\"Grant_Status\").\n",
    "  setOutputCol(\"status\").\n",
    "  fit(grants)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.VectorAssembler\r\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_e02f15c634ba, handleInvalid=error, numInputCols=7\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val assembler = new VectorAssembler().\n",
    "  setInputCols(Array(\n",
    "    \"Value_index\"\n",
    "    ,\"Category_index\"\n",
    "    ,\"PHDs\"\n",
    "    ,\"paperscore\"\n",
    "    ,\"teamsize\"\n",
    "    ,\"successes\"\n",
    "    ,\"failures\"\n",
    "  )).setOutputCol(\"assembled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.RandomForestClassifier\r\n",
       "import org.apache.spark.ml.classification.RandomForestClassificationModel\r\n",
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_b4afc126417c\r\n",
       "import org.apache.spark.ml.Pipeline\r\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_24a3229c37aa\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.classification.RandomForestClassificationModel\n",
    "\n",
    "val rf = new RandomForestClassifier().\n",
    "  setFeaturesCol(\"assembled\").\n",
    "  setLabelCol(\"status\").\n",
    "  setSeed(42)\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "val pipeline = new Pipeline().setStages(Array(\n",
    "    value_band_indexer,\n",
    "    category_indexer,\n",
    "    label_indexer,\n",
    "    assembler,\n",
    "    rf)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\r\n",
       "auc_eval: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = BinaryClassificationEvaluator: uid=binEval_34c90dcf5d9a, metricName=areaUnderROC, numBins=1000\r\n",
       "tr: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Grant_Application_ID: int, Grant_Status: int ... 7 more fields]\r\n",
       "te: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Grant_Application_ID: int, Grant_Status: int ... 7 more fields]\r\n",
       "training: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, Grant_Status: int ... 7 more fields]\r\n",
       "test: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, Grant_Status: int ... 7 more fields]\r\n",
       "model: org.apache.spark.ml.PipelineModel = pipeline_24a3229c37aa\r\n",
       "pipeline_results: org.apa...\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "val auc_eval = new BinaryClassificationEvaluator().\n",
    "  setLabelCol(\"status\").\n",
    "  setRawPredictionCol(\"rawPrediction\")\n",
    "\n",
    "auc_eval.getMetricName\n",
    "\n",
    "val tr = grants.filter(\"Grant_Application_ID < 6635\")\n",
    "val te = grants.filter(\"Grant_Application_ID >= 6635\")\n",
    "val training = tr.na.fill(0, Seq(\"PHDs\"))\n",
    "val test = te.na.fill(0, Seq(\"PHDs\"))\n",
    "\n",
    "val model = pipeline.fit(training)\n",
    "val pipeline_results = model.transform(test)\n",
    "auc_eval.evaluate(pipeline_results)\n",
    "\n",
    "rf.extractParamMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.tuning.ParamGridBuilder\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\trfc_b4afc126417c-maxDepth: 2,\r\n",
       "\trfc_b4afc126417c-numTrees: 1\r\n",
       "}, {\r\n",
       "\trfc_b4afc126417c-maxDepth: 2,\r\n",
       "\trfc_b4afc126417c-numTrees: 20\r\n",
       "}, {\r\n",
       "\trfc_b4afc126417c-maxDepth: 5,\r\n",
       "\trfc_b4afc126417c-numTrees: 1\r\n",
       "}, {\r\n",
       "\trfc_b4afc126417c-maxDepth: 5,\r\n",
       "\trfc_b4afc126417c-numTrees: 20\r\n",
       "})\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "\n",
    "val paramGrid = new ParamGridBuilder().\n",
    "  addGrid(rf.maxDepth, Array(2, 5)).\n",
    "  addGrid(rf.numTrees, Array(1, 20)).\n",
    "  build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.tuning.CrossValidator\r\n",
       "cv: org.apache.spark.ml.tuning.CrossValidator = cv_132be5ad91fb\r\n",
       "cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = CrossValidatorModel: uid=cv_132be5ad91fb, bestModel=pipeline_24a3229c37aa, numFolds=3\r\n",
       "cv_results: org.apache.spark.sql.DataFrame = [Grant_Application_ID: int, Grant_Status: int ... 14 more fields]\r\n",
       "res3: Array[Double] = Array(0.6954426991157221, 0.8729449693948864, 0.8972594318668786, 0.922704923185537)\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.CrossValidator\n",
    "\n",
    "val cv = new CrossValidator().\n",
    "  setEstimator(pipeline).\n",
    "  setEvaluator(auc_eval).\n",
    "  setEstimatorParamMaps(paramGrid).\n",
    "  setNumFolds(3)\n",
    "\n",
    "val cvModel = cv.fit(training)\n",
    "\n",
    "val cv_results = cvModel.transform(test)\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Winning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.param.ParamMap\r\n",
       "import org.apache.spark.ml.tuning.CrossValidatorModel\r\n",
       "defined class BestParamMapCrossValidatorModel\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.param.ParamMap\n",
    "import org.apache.spark.ml.tuning.CrossValidatorModel\n",
    "\n",
    "implicit class BestParamMapCrossValidatorModel(cvModel: CrossValidatorModel)\n",
    "{\n",
    "  def bestEstimatorParamMap: ParamMap = cvModel.getEstimatorParamMaps.zip(cvModel.avgMetrics).maxBy(_._2)._1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using bestEstimatorParamMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\trfc_b4afc126417c-maxDepth: 5,\n",
      "\trfc_b4afc126417c-numTrees: 20\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(cvModel.bestEstimatorParamMap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bestPipelineModel: org.apache.spark.ml.PipelineModel = pipeline_24a3229c37aa\r\n",
       "res5: Array[org.apache.spark.ml.Transformer] = Array(StringIndexerModel: uid=strIdx_2ac4c5292f7f, handleInvalid=error, StringIndexerModel: uid=strIdx_8ce2dc20f1b0, handleInvalid=error, StringIndexerModel: uid=strIdx_a826b719fc96, handleInvalid=error, VectorAssembler: uid=vecAssembler_e02f15c634ba, handleInvalid=error, numInputCols=7, RandomForestClassificationModel: uid=rfc_b4afc126417c, numTrees=20, numClasses=2, numFeatures=7)\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bestPipelineModel = cvModel.bestModel.asInstanceOf[org.apache.spark.ml.PipelineModel]\n",
    "bestPipelineModel.stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Winning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bestRandomForest: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel: uid=rfc_b4afc126417c, numTrees=20, numClasses=2, numFeatures=7\r\n",
       "res6: String =\r\n",
       "\"RandomForestClassificationModel: uid=rfc_b4afc126417c, numTrees=20, numClasses=2, numFeatures=7\r\n",
       "  Tree 0 (weight 1.0):\r\n",
       "    If (feature 0 in {2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0})\r\n",
       "     If (feature 1 in {1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,11.0,12.0,13.0})\r\n",
       "      If (feature 4 <= 7.5)\r\n",
       "       Predict: 0.0\r\n",
       "      Else (feature 4 > 7.5)\r\n",
       "       Predict: 1.0\r\n",
       "     Else (feature 1 not in {1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,11.0,12.0,13.0})\r\n",
       "      If (feature 0 in {9.0,13.0,14.0})\r\n",
       "       If (feature 4 <= 3.5)\r\n",
       "        If (feature 0 in {13.0})\r\n",
       "         Predict: 1.0\r\n",
       "  ...\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bestRandomForest = bestPipelineModel.stages(4).asInstanceOf[RandomForestClassificationModel]\n",
    "bestRandomForest.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### totalNumNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Int = 736\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestRandomForest.totalNumNodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: org.apache.spark.ml.linalg.Vector = (7,[0,1,2,3,4,5,6],[0.20428274601717972,0.17210062921296593,0.01360393415994755,0.025440963724379338,0.003365188203866553,0.21815889499218416,0.3630476436894768])\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestRandomForest.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up\n",
    "\n",
    "* Using the default parameters, we had an area under the ROC curve of 0.909\n",
    "* After a grid search, we got that up to 0.926\n",
    "* Running the grid search on a cluster was a real timesaver\n",
    "* Not all of our features proved very useful; maybe you can do better!\n",
    "\n",
    "### Module Summary\n",
    "\n",
    "* Having completed this module about Predicting Grant Applications, you should be able to:\n",
    "  - Understand how to fit together the functions available in Spark's machine learning libraries to solve real problems\n",
    "  - Fit models in a fraction of the time, using a Spark cluster\n",
    "\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
